options
{
	// Use \ u escapes in streams AND use a reader for the query
	// => get both raw and escaped unicode
	JAVA_UNICODE_ESCAPE = true;
	UNICODE_INPUT = false;

	STATIC = false;
	// DEBUG_PARSER = true;
	// DEBUG_TOKEN_MANAGER = true;
}

PARSER_BEGIN(JavaCCParser)
package org.semanticweb.vlog4j.parser.javacc;

import java.io.File;
import java.io.InputStream;
import java.io.IOException;
import java.net.URL;
import java.net.MalformedURLException;

import java.util.List;
import java.util.Deque;
import java.util.ArrayList;
import java.util.ArrayDeque;
import java.util.LinkedList;

import org.semanticweb.vlog4j.parser.ParsingException;
import org.semanticweb.vlog4j.parser.javacc.JavaCCParserBase;
import org.semanticweb.vlog4j.core.exceptions.PrefixDeclarationException;

import org.semanticweb.vlog4j.core.model.api.Statement;
import org.semanticweb.vlog4j.core.model.api.Rule;
import org.semanticweb.vlog4j.core.model.api.Literal;
import org.semanticweb.vlog4j.core.model.api.NegativeLiteral;
import org.semanticweb.vlog4j.core.model.api.PositiveLiteral;
import org.semanticweb.vlog4j.core.model.api.Fact;
import org.semanticweb.vlog4j.core.model.api.Term;
import org.semanticweb.vlog4j.core.model.api.Constant;
import org.semanticweb.vlog4j.core.model.api.DataSource;
import org.semanticweb.vlog4j.core.model.api.PrefixDeclarations;
import org.semanticweb.vlog4j.core.reasoner.implementation.CsvFileDataSource;
import org.semanticweb.vlog4j.core.reasoner.implementation.RdfFileDataSource;
import org.semanticweb.vlog4j.core.reasoner.implementation.SparqlQueryResultDataSource;

import org.semanticweb.vlog4j.core.model.implementation.Expressions;


public class JavaCCParser extends JavaCCParserBase
{
	private SubParserFactory getSubParserFactory() {
		return new SubParserFactory(this);
	}

	public void ensureEndOfInput() throws ParseException {
		jj_consume_token(EOF);
	}
}

PARSER_END(JavaCCParser)

TOKEN_MGR_DECLS : {
	// use initializer block to work around auto-generated constructors.
	{
		states = new ArrayDeque<Integer>();
	}

	Deque<Integer> states;

	void pushState() {
	  states.push(curLexState);
	}

	void popState() {
		SwitchTo(states.pop());
	}
}


void parse() throws PrefixDeclarationException : {
} {
	( base() )?
	( prefix() )*
	( source() )*
	( statement() )*
	< EOF >
}

void base() throws PrefixDeclarationException : {
	Token iri;
} {
	< BASE > iri = < IRI_ABSOLUTE > < DOT > {
		setBase(iri.image);
	}
}

void prefix() throws PrefixDeclarationException : {
	Token pn;
	String iri;
} {
	< PREFIX > pn = < PNAME_NS > iri = absoluteIri() < DOT > {
		setPrefix(pn.image, iri);
	}
}

String absoluteIri() throws PrefixDeclarationException : {
	Token iri;
} {
	iri = < IRI_ABSOLUTE > { return absolutizeIri(iri.image); }
  | iri = < PNAME_LN > { return resolvePrefixedName(iri.image); }
}

String quotedIri() throws PrefixDeclarationException : {
	String iri;
} {
	iri = absoluteIri() { return "<" +  iri + ">"; }
}

void source() throws PrefixDeclarationException : {
    String predicateName;
    DataSource dataSource;
    Token arity;
} {
    < SOURCE > predicateName = predicateName() arity = < ARITY > < COLON > dataSource = dataSource() < DOT >
    {
      int nArity;
      // Do not catch NumberFormatException: < INTEGER > matches must parse as int in Java!
      nArity = Integer.parseInt(arity.image);

      addDataSource(predicateName, nArity, dataSource);
    }
}

DataSource dataSource() throws PrefixDeclarationException : {
  Token sourceName;
  List< String > arguments;
} {
	( sourceName = < ARGUMENT_NAME >
	| sourceName = < VARORPREDNAME > ) < LPAREN > arguments = Arguments() < RPAREN > {
		return parseDataSourceSpecificPartOfDataSourceDeclaration(sourceName.image, arguments, getSubParserFactory());
    }
}

void statement() throws PrefixDeclarationException : {
    Statement statement;
    resetVariableSets();
} {
    ( LOOKAHEAD(rule()) statement = rule()
	| statement = fact(FormulaContext.HEAD) ) {
		addStatement(statement);
	}
}

Rule rule() throws PrefixDeclarationException : {
    List < PositiveLiteral > head;
    List < Literal > body;
} {
    head = listOfPositiveLiterals(FormulaContext.HEAD) < ARROW > body = listOfLiterals(FormulaContext.BODY) < DOT > {
        // check that the intersection between headExiVars and BodyVars is empty
        for (String variable : headExiVars) {
          if (bodyVars.contains(variable))
            throw new ParseException("Malformed rule " + head + " :- " + body + "\nExistential variable " + variable + " also used in rule body.");
        }

        // check that bodyVars contains headUniVars
        for (String variable : headUniVars) {
          if (!bodyVars.contains(variable))
            throw new ParseException("Unsafe rule " + head + " :- " + body  + "\nUniversal variable " + variable + " occurs in head but not in body.");
        }

        return Expressions.makeRule(Expressions.makePositiveConjunction(head), Expressions.makeConjunction(body));
    }
}

List < PositiveLiteral > listOfPositiveLiterals(FormulaContext context) throws PrefixDeclarationException : {
    PositiveLiteral l;
    List < PositiveLiteral > list = new ArrayList < PositiveLiteral > ();
} {
	l = positiveLiteral(context) { list.add(l); } ( < COMMA > l = positiveLiteral(context) { list.add(l); } )* {
		return list;
	}
}

List < Literal > listOfLiterals(FormulaContext context) throws PrefixDeclarationException : {
    Literal l;
    List < Literal > list = new ArrayList < Literal > ();
} {
    l = literal(context) { list.add(l); } ( < COMMA > l = literal(context) { list.add(l); } )* {
		return list;
	}
}

Literal literal(FormulaContext context) throws PrefixDeclarationException : {
    Literal l;
} {
    ( l = positiveLiteral(context)
	| l = negativeLiteral(context) ) {
		return l;
	}
}

PositiveLiteral positiveLiteral(FormulaContext context) throws PrefixDeclarationException : {
    Token t;
    List < Term > terms;
    String predicateName;
} {
    predicateName = predicateName() < LPAREN > terms = listOfTerms(context) < RPAREN > {
		return Expressions.makePositiveLiteral(predicateName, terms);
	}
}

Fact fact(FormulaContext context) throws PrefixDeclarationException : {
    Token t;
    List < Term > terms;
    String predicateName;
} {
    predicateName = predicateName() < LPAREN > terms = listOfTerms(context) < RPAREN > < DOT > {
      try {
      	return Expressions.makeFact(predicateName, terms);
      } catch (IllegalArgumentException e) {
		  throw makeParseExceptionWithCause("Error parsing fact: " + e.getMessage(), e);
      }
    }
}

NegativeLiteral negativeLiteral(FormulaContext context) throws PrefixDeclarationException : {
    List < Term > terms;
    String predicateName;
} {
    < TILDE > predicateName = predicateName() < LPAREN > terms = listOfTerms(context) < RPAREN > {
		return Expressions.makeNegativeLiteral(predicateName, terms);
	}
}

List < Term > listOfTerms(FormulaContext context) throws PrefixDeclarationException : {
    Term t;
    List < Term > list = new ArrayList < Term > ();
} {
    t = term(context) { list.add(t); } ( < COMMA > t = term(context) { list.add(t); } )* {
		return list;
	}
}

String predicateName() throws PrefixDeclarationException : {
    Token t;
	String s;
} {
	s = absoluteIri() { return s; }
  |	t = < VARORPREDNAME > { return absolutizeIri(t.image); }
}

Term term(FormulaContext context) throws PrefixDeclarationException : {
    Token t;
    String s;
    Constant c;
	Term tt;
} {
    s = absoluteIri() { return createConstant(s); }
  | t = < VARORPREDNAME > { return createConstant(t.image); }
  | c = NumericLiteral() { return c; }
  | c = RDFLiteral() { return c; }
  | t = < UNIVAR > {
        s = t.image.substring(1);
        if (context == FormulaContext.HEAD)
            headUniVars.add(s);
        else if (context == FormulaContext.BODY)
            bodyVars.add(s);
        return Expressions.makeUniversalVariable(s);
    }
  | t = < EXIVAR > {
        s = t.image.substring(1);
        if (context == FormulaContext.HEAD)
            headExiVars.add(s);
        if (context == FormulaContext.BODY)
            throw new ParseException("Existentialy quantified variables can not appear in the body. Line: " + t.beginLine + ", Column: "+ t.beginColumn);
        return Expressions.makeExistentialVariable(s);
    }
  | try {
		tt = ConfigurableLiteral () { return tt; }
	} catch (ParsingException e) {
		throw new ParseException("Invalid configurable literal expression: " + e.getMessage());
	}
}

Constant NumericLiteral() : {
    Token t;
} {
    t = < INTEGER > { return createConstant(t.image, PrefixDeclarations.XSD_INTEGER); }
  | t = < DECIMAL > { return createConstant(t.image, PrefixDeclarations.XSD_DECIMAL); }
  | t = < DOUBLE > { return createConstant(t.image, PrefixDeclarations.XSD_DOUBLE); }
}

Constant RDFLiteral() throws PrefixDeclarationException : {
    String lex;
    Token lang = null;   // Optional lang tag and datatype.
    String dt = null;
} {
    lex = String() ( lang = < LANGTAG > | < DATATYPE > dt = absoluteIri() )? {
		if (lang != null) {
			return Expressions.makeLanguageStringConstant(lex, lang.image);
		}
		return createConstant(lex, dt);
	}
}

Term ConfigurableLiteral() throws ParsingException : {
	Token t;
} {
	( LOOKAHEAD( < PIPE_DELIMITED_LITERAL >,
				 { isConfigurableLiteralRegistered(ConfigurableLiteralDelimiter.PIPE) } )
	 t = < PIPE_DELIMITED_LITERAL > {
		return parseConfigurableLiteral(ConfigurableLiteralDelimiter.PIPE, t.image, getSubParserFactory());
	 }
	 | LOOKAHEAD( < HASH_DELIMITED_LITERAL >,
				  { isConfigurableLiteralRegistered(ConfigurableLiteralDelimiter.HASH) } )
	 t = < HASH_DELIMITED_LITERAL > {
		return parseConfigurableLiteral(ConfigurableLiteralDelimiter.HASH, t.image, getSubParserFactory());
	 }
	 | LOOKAHEAD( < PAREN_DELIMITED_LITERAL >,
				  { isConfigurableLiteralRegistered(ConfigurableLiteralDelimiter.PAREN) } )
	 t = < PAREN_DELIMITED_LITERAL > {
		return parseConfigurableLiteral(ConfigurableLiteralDelimiter.PAREN, t.image, getSubParserFactory());
	 }
	 | LOOKAHEAD( < BRACE_DELIMITED_LITERAL >,
				  { isConfigurableLiteralRegistered(ConfigurableLiteralDelimiter.BRACE) } )
	 t = < BRACE_DELIMITED_LITERAL > {
		return parseConfigurableLiteral(ConfigurableLiteralDelimiter.BRACE, t.image, getSubParserFactory());
	 }
	 | LOOKAHEAD( < BRACKET_DELIMITED_LITERAL >,
	 			  { isConfigurableLiteralRegistered(ConfigurableLiteralDelimiter.BRACKET) } )
	 t = < BRACKET_DELIMITED_LITERAL > {
	 	return parseConfigurableLiteral(ConfigurableLiteralDelimiter.BRACKET, t.image, getSubParserFactory());
	 }
	 )
}

String String() : {
    Token t;
} {
    ( t = < SINGLE_QUOTED_STRING >
    | t = < DOUBLE_QUOTED_STRING >
    | t = < TRIPLE_QUOTED_STRING >
    | t = < SIXFOLD_QUOTED_STRING >
	) { return unescapeStr(t.image, t.beginLine, t.beginColumn); }
}

LinkedList< String > Arguments() throws PrefixDeclarationException : {
    String str;
    LinkedList< String > rest = new LinkedList< String >();
} {
    ( str = String()
	| str = quotedIri()) [< COMMA > rest = Arguments()] {
		rest.addFirst(str);
        return rest;
    }
}

String PrefixedName() throws PrefixDeclarationException : {
    Token t;
} {
	t = < PNAME_LN > { return resolvePrefixedName(t.image); }
}

// ------------------------------------------

// Whitespace
< * > SKIP : {
  < WHITESPACE : [ " ", "\t", "\n", "\r", "\f" ] >
}

// Comments
< * > SKIP : {
  < COMMENT : "%" ( ~[ "\n" ] )* "\n" >
}

MORE : {
  "@": DIRECTIVE
}

< DEFAULT, TERM, DIRECTIVE_ARGUMENTS > MORE : {
	"<" { pushState(); } : ABSOLUTE_IRI
}

< DEFAULT, BODY, TERM, DIRECTIVE_ARGUMENTS > TOKEN : {
  < VARORPREDNAME : < A2Z> (< A2ZN >)* >
  | < #A2Z : [ "a"-"z", "A"-"Z" ] >
  | < #A2ZN : [ "a"-"z", "A"-"Z", "0"-"9" ] >
  | < PNAME_LN : (< PN_PREFIX >)? ":" < PN_LOCAL > >
  | < PNAME_NS : < PN_PREFIX > ":" >
  | < #PN_CHARS_BASE : [ "a"-"z", "A"-"Z", "\u00c0"-"\u00d6",
						 "\u00d8"-"\u00f6", "\u00f8"-"\u02ff",
						 "\u0370"-"\u037d", "\u037f"-"\u1fff",
						 "\u200c"-"\u200d", "\u2070"-"\u218f",
						 "\u2c00"-"\u2fef", "\u3001"-"\ud7ff",
						 "\uf900"-"\ufffd" ] >
  | < #PN_CHARS_U : < PN_CHARS_BASE > | "_" >
  | < #PN_CHARS : ( < PN_CHARS_U > | [ "-", "0"-"9", "\u00b7",
									   "\u0300"-"\u036f",
									   "\u203f"-"\u2040" ] ) >
  | < #PN_PREFIX : < PN_CHARS_BASE >
		( ( < PN_CHARS > | "." )* < PN_CHARS > )? >
  | < #PN_LOCAL : ( < PN_CHARS_U > | [ ":", "0"-"9" ] )
		( ( < PN_CHARS > | [ ".", ":" ] )* < PN_CHARS > )? >
  |	< COMMA : "," >
  | < RPAREN : ")" > { popState(); }
}

< DEFAULT, BODY , DIRECTIVE_ARGUMENTS > TOKEN : {
	< LPAREN : "(" > {
		pushState();

		if (curLexState == DEFAULT || curLexState == BODY) {
			SwitchTo(TERM);
		}
	}
}

< TERM, DIRECTIVE_ARGUMENTS > TOKEN : {
  < INTEGER : (< SIGN >)? < DIGITS > >
  | < DECIMAL : (< SIGN >)? ( < DIGITS > "." (< DIGIT >)*
							  | "." < DIGITS > ) >
  | < DOUBLE : (< SIGN >)? ( < DIGITS > "." (< DIGIT >)* < EXPONENT >
                           | "." (< DIGITS >) (< EXPONENT >)
                           | < DIGITS > < EXPONENT > ) >
  | < #SIGN : [ "+", "-" ] >
  | < #DIGIT : [ "0"-"9" ] >
  | < #DIGITS : (< DIGIT >)+ >
  | < #EXPONENT : [ "e", "E" ] (< SIGN >)? < DIGITS > >
  | < COLON : ":" >
}

TOKEN : {
  < ARROW : ":-" > : BODY
}

< DEFAULT, BODY > TOKEN : {
  < TILDE : "~" >
}

< ABSOLUTE_IRI > TOKEN : {
	< IRI_ABSOLUTE : (~[ ">", "<", "\"", "{", "}", "^", "\\", "|", "`", "\u0000"-"\u0020" ])* ">" > {
			  matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 1);
			  popState();
		  }
}

< DIRECTIVE > TOKEN : {
    < BASE : "base" > : DIRECTIVE_ARGUMENTS
  | < PREFIX : "prefix" > : DIRECTIVE_ARGUMENTS
  | < SOURCE : "source" > : DIRECTIVE_ARGUMENTS
  | < CUSTOM : < DIRECTIVENAME > > : DIRECTIVE_ARGUMENTS
  | < DIRECTIVENAME : [ "a"-"z", "A"-"Z" ] ([ "a"-"z", "A"-"Z", "0"-"9", "-", "_" ])* >
}

< DEFAULT, BODY, DIRECTIVE_ARGUMENTS > TOKEN : {
	< DOT : "." > : DEFAULT
}

< DIRECTIVE_ARGUMENTS > TOKEN : {
  < ARITY : "[" < INTEGER > "]" > {
			  matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 1);
		  }
  | < ARGUMENT_NAME : < DIRECTIVENAME > >
}

< TERM > TOKEN : {
	< UNIVAR : "?" < VARORPREDNAME > >
  | < EXIVAR : "!" < VARORPREDNAME > >
  | < LANGTAG : "@" ( < A2Z > )+ ( "-" ( < A2ZN > )+ )? > {
		matchedToken.image = JavaCCParserBase.stripChars(matchedToken.image, 1);
	}
  | < DATATYPE : "^^" >
}

< TERM, DIRECTIVE_ARGUMENTS > MORE : {
  < "'" > { pushState(); } : SINGLE_QUOTED
  | < "\"" > { pushState(); } : DOUBLE_QUOTED
  | < "'''" > { pushState(); }: TRIPLE_QUOTED
  | < "\"\"\"" > { pushState(); } : SIXFOLD_QUOTED
  | < "|" > { pushState(); } : PIPE_DELIMITED
  | < "#" > { pushState(); } : HASH_DELIMITED
  | < < LPAREN > > { pushState(); } : PAREN_DELIMITED
  | < "{" > { pushState(); } : BRACE_DELIMITED
  | < "[" > { pushState(); } : BRACKET_DELIMITED
}

< PIPE_DELIMITED > TOKEN : {
	< PIPE_DELIMITED_LITERAL : ( ~ [ "|" ] )* "|" > {
		popState();
		matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 1);
	}
}

< HASH_DELIMITED > TOKEN : {
	< HASH_DELIMITED_LITERAL : ( ~ [ "#" ] )* "#" > {
		popState();
		matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 1);
	}
}

< PAREN_DELIMITED > TOKEN : {
	< PAREN_DELIMITED_LITERAL : ( < UNPAREN > ( "(" < UNPAREN > ")" )* )* < UNPAREN > ")" > {
		popState();
		matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 1);
	}
  | < #UNPAREN : ( ~ [ "(", ")" ] )* >
}

< BRACE_DELIMITED > TOKEN : {
	< BRACE_DELIMITED_LITERAL : ( < UNBRACE > ( "{" < UNBRACE > "}" )* )* < UNBRACE > "}" > {
		popState();
		matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 1);
	}
  | < #UNBRACE : (~ [ "{", "}" ] )* >
}

< BRACKET_DELIMITED > TOKEN : {
	< BRACKET_DELIMITED_LITERAL : ( < UNBRACKET > ( "[" < UNBRACKET >  "]" )* )* < UNBRACKET > "]" > {
		popState();
		matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 1);
	}
  | < #UNBRACKET : ( ~ [ "[", "]" ] )* >
}

< SINGLE_QUOTED > TOKEN : {
	< SINGLE_QUOTED_STRING : ( ~[ "'", "\\", "\n", "\r" ]
							 | < ESCAPE_SEQUENCE > )* "'" > {
		popState();
		matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 1);
	}
}

< DOUBLE_QUOTED > TOKEN : {
	< DOUBLE_QUOTED_STRING : ( ~[ "\"", "\\", "\n", "\r" ]
							 | < ESCAPE_SEQUENCE > )* "\"" > {
		popState();
		matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 1);
	}
}

< TRIPLE_QUOTED > TOKEN : {
	< TRIPLE_QUOTED_STRING : ( ~[ "'", "\\" ]
							 | < ESCAPE_SEQUENCE >
							 | ( "'" ~[ "'" ] )
							 | ( "''" ~[ "'" ] ) )* "'''" > {
		popState();
		matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 3);
	}
}

< SIXFOLD_QUOTED > TOKEN : {
	< SIXFOLD_QUOTED_STRING : ( ~[ "\"", "\\" ]
							  | < ESCAPE_SEQUENCE >
							  | ( "\"" ~[ "\"" ] )
							  | ( "\"\"" ~[ "\"" ] ) )* "\"\"\"" > {
		popState();
		matchedToken.image = JavaCCParserBase.stripDelimiters(matchedToken.image, 3);
	}
}

< SINGLE_QUOTED, DOUBLE_QUOTED, TRIPLE_QUOTED, SIXFOLD_QUOTED > MORE : {
	< ESCAPE_SEQUENCE : "\\" [ "t", "b", "n", "r", "f", "\\", "\"", "'" ] >
}
